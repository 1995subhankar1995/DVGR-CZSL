{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SUN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZBrYdA8lMavHqHVWMFaiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DVGR-CZSL/DVGR-CZSL/blob/main/SUN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG3rZItCGQN-"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.autograd import Variable\r\n",
        "from copy import deepcopy\r\n",
        "from sklearn.preprocessing import normalize\r\n",
        "import glob, os\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i538DfRSGYY8"
      },
      "source": [
        "\r\n",
        "class encoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(encoder, self).__init__()\r\n",
        "    self.fc1 = torch.nn.Linear(2048, 1000)\r\n",
        "    self.fc2 = torch.nn.Linear(1000, 500)\r\n",
        "    self.fc3 = torch.nn.Linear(500, 100)\r\n",
        "    self.rel = torch.nn.ReLU()\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.fc1(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.fc2(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.fc3(x)\r\n",
        "    return x\r\n",
        "class decoder(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(decoder, self).__init__()\r\n",
        "    self.n_e = 102\r\n",
        "    self.n_y = 708\r\n",
        "    self.fc1 = torch.nn.Linear(50 + self.n_e + self.n_y, 500)\r\n",
        "    self.fc2 = torch.nn.Linear(500, 1000)\r\n",
        "    self.fc3 = torch.nn.Linear(1000, 2048 + 708 + 102)\r\n",
        "    self.rel = torch.nn.ReLU()\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.fc1(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.fc2(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.fc3(x)\r\n",
        "    x_out = x[:, :2048]\r\n",
        "    y_out  = x[:, 2048: 2048 + 708]\r\n",
        "    em_out = x[:, (2048 + 708):]\r\n",
        "    return x_out, y_out, em_out\r\n",
        "\r\n",
        "class VAE(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(VAE, self).__init__()\r\n",
        "    self.en = encoder()\r\n",
        "    self.de = decoder()\r\n",
        "    self.eps = eps\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, cls_att):\r\n",
        "    #print(x.shape, 'aa')\r\n",
        "    x = self.en(x)\r\n",
        "    mu = x[:, :50]\r\n",
        "    logvar = x[:, 50:]\r\n",
        "    std = torch.exp(0.5 * logvar)\r\n",
        "    z = mu + self.eps * std\r\n",
        "    z1 = torch.cat((z, one_hot), axis = 1)\r\n",
        "    z1 = torch.cat((z1, cls_att), axis = 1)\r\n",
        "    return self.de(z1), mu, logvar\r\n",
        "\r\n",
        "\r\n",
        "class private(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(private, self).__init__()\r\n",
        "    self.task = torch.nn.ModuleList()\r\n",
        "    self.eps = eps\r\n",
        "    for _ in range(15):\r\n",
        "      self.task.append(VAE(self.eps))\r\n",
        "\r\n",
        "  def forward(self, x, one_hot, cls_att, task_id):\r\n",
        "    return self.task[task_id].forward(x, one_hot, cls_att)\r\n",
        "\r\n",
        "class NET(nn.Module):\r\n",
        "  def __init__(self, eps):\r\n",
        "    super(NET, self).__init__()\r\n",
        "    self.eps = eps\r\n",
        "    #self.shared = VAE(self.eps)\r\n",
        "    self.private = private(self.eps)\r\n",
        "    #self.fc1 = torch.nn.Linear(4096, 2048)\r\n",
        "    self.head = torch.nn.ModuleList()\r\n",
        "    for _ in range(15):\r\n",
        "      self.head.append(\r\n",
        "          nn.Sequential(\r\n",
        "              nn.Linear(2048, 1000),\r\n",
        "              nn.Linear(1000, 500),\r\n",
        "              nn.Linear(500, 708)\r\n",
        "          )\r\n",
        "      )\r\n",
        "  def forward(self, x, one_hot, cls_att, task_id):\r\n",
        "    #s_x, s_mu, s_logvar = self.shared(x, one_hot, cls_att)\r\n",
        "    #print(s_x.shape)\r\n",
        "    p_out, p_mu, p_logvar = self.private(x, one_hot, cls_att, task_id)\r\n",
        "    #x = torch.cat((s_x, p_x), axis = 1)\r\n",
        "    #x = self.fc1(x)\r\n",
        "\r\n",
        "    return self.head[task_id].forward(x), (p_out, p_mu, p_logvar)\r\n",
        "\r\n",
        "  def common_features(self, z, task_id):\r\n",
        "    x_p, _, _ = self.private.task[task_id].de(z)\r\n",
        "    #x_s = self.shared.de(z)\r\n",
        "    #x = torch.cat((x_s, x_p), axis = 1)\r\n",
        "    return  x_p #self.fc1(x)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z254E_sXGdsu"
      },
      "source": [
        "path = 'FolderPath'\r\n",
        "train_data_path = path + '/trainData'\r\n",
        "train_label_path = path + '/trainLabels'\r\n",
        "train_attr_path = path + '/trainAttributes'\r\n",
        "test_data_path = path + '/testData'\r\n",
        "test_label_path = path + '/testLabels'\r\n",
        "test_attr_path = path + '/testAttributes'\r\n",
        "attributes_path = path + '/dataAttributes'\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QG9kBLQJkyj"
      },
      "source": [
        "def dataprocess(data_path):\r\n",
        "  with open(data_path, 'rb') as fopen:\r\n",
        "     #contents = np.load(fopen, allow_pickle=True, encoding='bytes')\r\n",
        "    contents = np.load(fopen, allow_pickle=True, encoding='latin1')\r\n",
        "    return contents\r\n",
        "\r\n",
        "trainData1 = dataprocess(train_data_path)\r\n",
        "trainLabels1 = dataprocess(train_label_path)\r\n",
        "trainLabelsVectors1 = dataprocess(train_attr_path)\r\n",
        "testData1 = dataprocess(test_data_path)\r\n",
        "testLabels1 = dataprocess(test_label_path)\r\n",
        "testlabelsvectors1 = dataprocess(test_attr_path)\r\n",
        "ATTR = dataprocess(attributes_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHLc91IBJm3j"
      },
      "source": [
        "class CLASSIFIER(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(CLASSIFIER, self).__init__()\r\n",
        "    self.fc1 = torch.nn.Linear(2048, 1500)\r\n",
        "    self.fc2 = torch.nn.Linear(1500, 1000)\r\n",
        "    self.fc3 = torch.nn.Linear(1000, 708)\r\n",
        "    self.drop = nn.Dropout(p = 0.2)\r\n",
        "    self.rel = torch.nn.ReLU()\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    #print(x.shape, '254')\r\n",
        "    x = self.fc1(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.fc2(x)\r\n",
        "    x = self.rel(x)\r\n",
        "    x = self.drop(x)\r\n",
        "    x = self.fc3(x)\r\n",
        "    return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glWBF69kJody"
      },
      "source": [
        "from sklearn.preprocessing import normalize\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "import random\r\n",
        "\r\n",
        "\r\n",
        "class CL_VAE():\r\n",
        "  def __init__(self):\r\n",
        "    super(CL_VAE, self).__init__()\r\n",
        "\r\n",
        "    self.batch_size = 64\r\n",
        "    self.num_classes = 708\r\n",
        "    self.build_model()\r\n",
        "    self.set_cuda()\r\n",
        "    self.criterion = torch.nn.CrossEntropyLoss()\r\n",
        "    self.recon = torch.nn.MSELoss()\r\n",
        "    #self.L1 = torch.nn.L1Loss()\r\n",
        "    self.L1 = torch.nn.MSELoss()\r\n",
        "    self.seen_acc = []\r\n",
        "    self.unseen_acc = []\r\n",
        "    self.hm_acc = []\r\n",
        "    self.overall_acc = []\r\n",
        "\r\n",
        "\r\n",
        "  def build_model(self):\r\n",
        "    self.eps = torch.randn(self.batch_size, 50)\r\n",
        "    self.eps = self.eps.cuda()\r\n",
        "    self.net = NET(self.eps)\r\n",
        "    pytorch_total_params = sum(p.numel() for p in self.net.parameters() if p.requires_grad)\r\n",
        "    print('pytorch_total_params:', pytorch_total_params)\r\n",
        "    \r\n",
        "  def set_cuda(self):\r\n",
        "    self.net.cuda()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def VAE_loss(self, recon, mu, sigma):\r\n",
        "    kl_div = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\r\n",
        "    #print('kl_div', kl_div.item())\r\n",
        "    return recon + kl_div\r\n",
        "\r\n",
        "  def train(self, all_traindata, all_trainlabels, all_testdata, all_testlabels, all_train_attr, all_test_attr, all_attr, total_tasks):\r\n",
        "    replay_classes = []\r\n",
        "    for i in range(total_tasks):\r\n",
        "      traindata = torch.tensor(all_traindata[i])\r\n",
        "      trainlabels = torch.tensor(all_trainlabels[i])\r\n",
        "      testdata = torch.tensor(all_testdata[i])\r\n",
        "      testlabels = torch.tensor(all_testlabels[i])\r\n",
        "      train_attr = torch.tensor(all_train_attr[i], dtype = torch.float32)\r\n",
        "      test_attr = torch.tensor(all_test_attr[i])\r\n",
        "      attr = torch.tensor(all_attr)\r\n",
        "      #print()\r\n",
        "\r\n",
        "      #print(trainlabels, 'avfr')\r\n",
        "      replay_classes.append(sorted(list(set(trainlabels.numpy().tolist()))))\r\n",
        "      if i + 1 == 1:\r\n",
        "        self.train_task(traindata.float(), trainlabels, train_attr, i)\r\n",
        "        #replay_classes.append(sorted(list(set(trainlabels.detach().numpy().tolist()))))\r\n",
        "        \r\n",
        "      else:\r\n",
        "        num_gen_samples = 50\r\n",
        "        #z_dim = 108\r\n",
        "        for m in range(i):\r\n",
        "          #print(replay_classes, 'replay_classes')\r\n",
        "          replay_trainlabels = []\r\n",
        "          for ii in replay_classes[m]:\r\n",
        "            for j in range(num_gen_samples):\r\n",
        "              replay_trainlabels.append(ii)\r\n",
        "          replay_trainlabels = torch.tensor(replay_trainlabels)\r\n",
        "          replay_trainlabels_onehot = self.one_hot(replay_trainlabels)\r\n",
        "          replay_attr = torch.tensor(attr[replay_trainlabels])\r\n",
        "          labels_attr = torch.cat((replay_trainlabels_onehot, replay_attr), axis = 1)\r\n",
        "\r\n",
        "          z = torch.randn(replay_trainlabels.shape[0], 50)\r\n",
        "\r\n",
        "          z_one_hot = torch.cat((z, labels_attr), axis = 1)\r\n",
        "          z_one_hot = z_one_hot.cuda()\r\n",
        "\r\n",
        "          replay_data = self.net.common_features(z_one_hot.float(), m).detach().cpu()\r\n",
        "\r\n",
        "          train_attr = torch.cat((replay_attr, train_attr), axis = 0)\r\n",
        "          traindata = torch.cat((replay_data, traindata), axis = 0)\r\n",
        "          trainlabels = torch.cat((replay_trainlabels, trainlabels))\r\n",
        "          testdata = torch.cat((testdata, torch.tensor(all_testdata[m])), axis = 0)\r\n",
        "          testlabels = torch.cat((testlabels, torch.tensor(all_testlabels[m])))\r\n",
        "        #print(sorted(list(set(testlabels.detach().numpy().tolist()))), 'aaa', i + 1)\r\n",
        "        self.train_task(traindata.float(), trainlabels, train_attr.float(), i)\r\n",
        "      testdata_unseen = []\r\n",
        "      testlabels_unseen = []\r\n",
        "      testdata_seen = []\r\n",
        "      testlabels_seen = []\r\n",
        "      for j in range(i + 1):\r\n",
        "        testdata_seen = testdata_seen + all_testdata[j]\r\n",
        "        testlabels_seen = testlabels_seen + all_testlabels[j]\r\n",
        "      for k in range(j + 1, total_tasks):\r\n",
        "        testdata_unseen = testdata_unseen + all_testdata[k]\r\n",
        "        testlabels_unseen = testlabels_unseen + all_testlabels[k]\r\n",
        "      \r\n",
        "      all_labels = sorted(list(set(testlabels_seen))) + sorted(list(set(testlabels_unseen)))\r\n",
        "      num_samples = 150\r\n",
        "      labels_list = []\r\n",
        "      for label in all_labels:\r\n",
        "        for l in range(num_samples):\r\n",
        "          labels_list.append(label)\r\n",
        "\r\n",
        "      attr_labels = attr[labels_list]\r\n",
        "      labels_list = torch.tensor(labels_list, dtype = torch.int64)\r\n",
        "      labels_list_onehot = self.one_hot(labels_list)\r\n",
        "      #print(labels_list_onehot.shape, 'aa', attr_labels.shape)\r\n",
        "      attr_labels_onehot = torch.cat((labels_list_onehot, attr_labels), axis = 1)\r\n",
        "      noise = torch.randn(len(labels_list), 50)\r\n",
        "      noise_others = torch.cat((noise, attr_labels_onehot), axis = 1)\r\n",
        "      noise_others = noise_others.float().cuda()\r\n",
        "      #print(noise_others.shape, 'aaa')\r\n",
        "      pseudodata  = self.net.common_features(noise_others, i)\r\n",
        "\r\n",
        "      test_seen = torch.tensor(testdata_seen)\r\n",
        "      \r\n",
        "      testlabels_s = torch.tensor(testlabels_seen)\r\n",
        "      testlabels_us = torch.tensor(testlabels_unseen)\r\n",
        "      #print(test_seen.shape, test_unseen.shape, testlabels_s.shape, testlabels_us.shape)\r\n",
        "      scaler = StandardScaler()\r\n",
        "      pseudodata = torch.from_numpy(scaler.fit_transform(pseudodata.detach().cpu().numpy())).cuda()\r\n",
        "      test_seen = torch.from_numpy(scaler.transform(test_seen.detach().numpy()))\r\n",
        "      if i < total_tasks - 1:\r\n",
        "        test_unseen = torch.tensor(testdata_unseen)\r\n",
        "        test_unseen = torch.from_numpy(scaler.transform(test_unseen.detach().numpy()))\r\n",
        "      #pseudodata = torch.from_numpy(normalize(pseudodata.detach().cpu().numpy(), axis = 1)).cuda()\r\n",
        "      #test_seen = torch.from_numpy(normalize(pseudodata.detach().cpu().numpy), axis = 1).to(cuda)\r\n",
        "      else:\r\n",
        "        test_unseen = None\r\n",
        "        testlabels_us = None\r\n",
        "\r\n",
        "\r\n",
        "      self.class_train(i, pseudodata, labels_list.cuda(), test_seen, testlabels_s, test_unseen, testlabels_us)\r\n",
        "\r\n",
        "  def dataloader(self, x, y, attr = None):\r\n",
        "    #x = x.detach().numpy()\r\n",
        "    #length = x.shape[0]\r\n",
        "    length = x.size()[0]\r\n",
        "    indices = np.arange(length)\r\n",
        "    random.shuffle(indices)\r\n",
        "    new_x = x[indices]\r\n",
        "    new_y = y[indices]\r\n",
        "    if attr is not None:\r\n",
        "      new_attr = attr[indices]\r\n",
        "      return new_x, new_y, new_attr\r\n",
        "    else:\r\n",
        "      return new_x, new_y\r\n",
        "#print(x.shape, dataloader(x, args))\r\n",
        "\r\n",
        "\r\n",
        "  def class_train(self, task_id, pseudodata, labels_list, test_seen, testlabels_s, test_unseen = None, testlabels_us = None):\r\n",
        "    pseudodata, labels_list = self.dataloader(pseudodata, labels_list)\r\n",
        "    #print(sorted(list(set(labels_list.detach().cpu().numpy()))), 'aaa')\r\n",
        "    self.CLASS = CLASSIFIER()\r\n",
        "    self.CLASS = self.CLASS.cuda()\r\n",
        "    class_opti = torch.optim.Adam(self.CLASS.parameters(), lr = 1e-4)\r\n",
        "    num_epochs = 25\r\n",
        "    batch_s = 64\r\n",
        "    num_iter = int(pseudodata.shape[0]/batch_s)\r\n",
        "    for e in range(num_epochs):\r\n",
        "      for i in range(num_iter):\r\n",
        "        self.CLASS.train()\r\n",
        "        self.CLASS.zero_grad()\r\n",
        "        batch_data = pseudodata[i * batch_s : (i + 1) * batch_s]\r\n",
        "        batch_label = labels_list[i * batch_s : (i + 1) * batch_s]\r\n",
        "        #print(batch_data.shape, '145')\r\n",
        "        out = self.CLASS(batch_data)\r\n",
        "        loss = self.criterion(out, batch_label)\r\n",
        "        loss.backward(retain_graph = True)\r\n",
        "        class_opti.step()\r\n",
        "          \r\n",
        "      #print('Epoch:', e + 1, 'Loss:', loss.item())\r\n",
        "    _, pred_s = torch.max(self.CLASS(test_seen.float().cuda()), axis = 1)\r\n",
        "    if testlabels_us is not None:\r\n",
        "      _, pred_us = torch.max(self.CLASS(test_unseen.float().cuda()), axis = 1)\r\n",
        "      pred_us = pred_us.detach().cpu()\r\n",
        "\r\n",
        "    pred_s = pred_s.detach().cpu()\r\n",
        "    \r\n",
        "    correct = {}\r\n",
        "    total = {}\r\n",
        "    for m in range(self.num_classes):\r\n",
        "      correct[m] = 0 \r\n",
        "      total[m] = 0\r\n",
        "    for m in range(test_seen.shape[0]):\r\n",
        "      #print(testlabels_s[m].item(), '44') #break\r\n",
        "      if pred_s[m].item() == testlabels_s[m].item():\r\n",
        "        #print(testlabels_s[m], '44')\r\n",
        "        correct[testlabels_s[m].item()] += 1\r\n",
        "      total[testlabels_s[m].item()] += 1\r\n",
        "    \r\n",
        "    acc1 = 0\r\n",
        "    acc2 = 0\r\n",
        "    num_s = 0\r\n",
        "    num_us = 0\r\n",
        "    seenclasses = sorted(list(set(testlabels_s.detach().cpu().numpy())))\r\n",
        "    \r\n",
        "    for m in seenclasses:\r\n",
        "      acc1 += correct[m]*1/total[m]\r\n",
        "      num_s += 1\r\n",
        "\r\n",
        "    acc1 = acc1/num_s\r\n",
        "    self.seen_acc.append(acc1)\r\n",
        "    \r\n",
        "\r\n",
        "    if testlabels_us is not None:\r\n",
        "      unseenclasses = sorted(list(set(testlabels_us.detach().cpu().numpy())))\r\n",
        "      for m in range(test_unseen.shape[0]):\r\n",
        "        if pred_us[m].item() == testlabels_us[m].item():\r\n",
        "          correct[testlabels_us[m].item()] += 1\r\n",
        "        total[testlabels_us[m].item()] += 1\r\n",
        "      for m in unseenclasses:\r\n",
        "        acc2 += correct[m]/total[m]\r\n",
        "        num_us += 1\r\n",
        "\r\n",
        "      acc2 = acc2/num_us\r\n",
        "      self.unseen_acc.append(acc2)\r\n",
        "      \r\n",
        "      self.hm_acc.append((2 * self.unseen_acc[task_id] * self.seen_acc[task_id])/(self.seen_acc[task_id] + self.unseen_acc[task_id]))\r\n",
        "      self.overall_acc.append((len(testlabels_s) * self.seen_acc[task_id] + len(testlabels_us) * self.unseen_acc[task_id])/(len(testlabels_s) + len(testlabels_us)))\r\n",
        "    \r\n",
        "    print('self.seen_acc:', np.mean(self.seen_acc))\r\n",
        "    print('self.unseen_acc:', np.mean(self.unseen_acc))\r\n",
        "    print('self.hm_acc:', np.mean(self.hm_acc))\r\n",
        "\r\n",
        "    \r\n",
        "      \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  def one_hot(self, labels):\r\n",
        "    matrix = torch.zeros(len(labels), self.num_classes)\r\n",
        "    rows = np.arange(len(labels))\r\n",
        "    matrix[rows, labels] = 1\r\n",
        "    return matrix \r\n",
        "\r\n",
        "  def model_save(self):\r\n",
        "    torch.save(self.net.state_dict(), os.path.join(self.net_path))\r\n",
        "\r\n",
        "\r\n",
        "  def train_task(self, traindata, trainlabels, train_attr, task_id):\r\n",
        "    traindata, trainlabels, train_attr = self.dataloader(traindata, trainlabels, train_attr)\r\n",
        "    net_opti = torch.optim.Adam(self.net.parameters(), lr = 1e-4)\r\n",
        "    num_iterations = int(traindata.shape[0]/self.batch_size)\r\n",
        "    num_epochs = 101 #51\r\n",
        "    for e in range(num_epochs):\r\n",
        "      for i in range(num_iterations):\r\n",
        "        self.net.zero_grad()\r\n",
        "        self.net.train()\r\n",
        "        \r\n",
        "\r\n",
        "        batch_data = traindata[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_label = trainlabels[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_train_attr = train_attr[i * self.batch_size : (i + 1)*self.batch_size]\r\n",
        "        batch_label_one_hot = self.one_hot(batch_label)\r\n",
        "        batch_data = batch_data.cuda()\r\n",
        "        batch_label = batch_label.cuda()\r\n",
        "        batch_label_one_hot = batch_label_one_hot.cuda()\r\n",
        "        batch_train_attr = batch_train_attr.cuda()\r\n",
        "\r\n",
        "        out, private_out = self.net(batch_data, batch_label_one_hot, batch_train_attr, task_id)\r\n",
        "        #s_x, s_mu, s_logvar = shared_out\r\n",
        "        p_out, p_mu, p_logvar = private_out\r\n",
        "        p_x, p_y, p_em = p_out\r\n",
        "        #print(p_y.shape, 'aa', p_em.shape)\r\n",
        "        #print(batch_label.shape, 'ap', batch_train_attr.shape)\r\n",
        "        #print(out.shape, '12', batch_label.shape, s_x.shape)\r\n",
        "        #p_y_onehot = self.one_hot(p_y)\r\n",
        "\r\n",
        "        cross_en_loss = self.criterion(out, batch_label)\r\n",
        "        y_loss = self.L1(p_y, batch_label_one_hot)\r\n",
        "        #print(p_em.shape, batch_train_attr.shape)\r\n",
        "        em_loss = self.L1(p_em, batch_train_attr)\r\n",
        "\r\n",
        "        #s_recon = self.recon(batch_data, s_x)\r\n",
        "        p_recon = self.recon(batch_data, p_x)\r\n",
        "\r\n",
        "        #s_VAE_loss = self.VAE_loss(s_recon, s_mu, s_logvar)\r\n",
        "        p_VAE_loss = self.VAE_loss(p_recon, p_mu, p_logvar)\r\n",
        "\r\n",
        "        all_loss =  cross_en_loss +  p_VAE_loss# + y_loss + em_loss#+  s_VAE_loss\r\n",
        "\r\n",
        "        all_loss.backward(retain_graph=True)\r\n",
        "        net_opti.step()\r\n",
        "      #print('epoch:', e + 1, 'task_loss', cross_en_loss.item(), 'p_VAE', p_VAE_loss.item())\r\n",
        "    \r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5LQGNm3JqhE"
      },
      "source": [
        "import time\r\n",
        "model = CL_VAE()\r\n",
        "st = time.time()\r\n",
        "model.train(trainData1, trainLabels1, testData1, testLabels1, trainLabelsVectors1, testlabelsvectors1, ATTR, 15)\r\n",
        "en = time.time()\r\n",
        "print(\"It takes:\", en - st, 'seconds')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}